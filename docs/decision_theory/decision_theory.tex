%%
% Please see https://bitbucket.org/rivanvx/beamer/wiki/Home for obtaining beamer.
%%
\documentclass[10pt]{beamer}

\renewcommand{\theenumi}{\alph{enumi}}
\title[Statistical Decision Theory]{Introduction to Decision Theory}

\author{Nishant D. Gurnani}
\date{July 4, 2020}


\begin{document}

% Title Page
\begin{frame}
\titlepage	
\end{frame}


% Big Picture
\begin{frame}
\frametitle{The Big Picture}
$$\text{financial markets} \rightarrow \text{data} \rightarrow \text{statistics} \rightarrow \text{inferences}$$
\newline 
As statisticians, we are tasked with turning the large amount of data generated by experiments and observations into inferences about the world.
\newline
\newline
This gives rise to a number of core statistical questions:
\newline

\begin{enumerate}

\item{Modeling: How do we capture the uncertainty in our data and the world that produced it?}
\newline
\item{Methodology: What are the right mathematical and computational tools that allow us to draw these statistical inferences?}
\newline
\item{Analysis: How do we compare and evaluate the statistical inferences we make and the procedures we use to make them? In particular, how do we do optimal inference?}	
\newline
\end{enumerate}

\end{frame}

% Framework 1
\begin{frame}
\frametitle{Decision Theory Framework}
Decision theory provides a framework to answer all of the core questions.
\newline
In particular, it allows us to formalize the notion of inference as a \textbf{decision problem} consisting of three key ingredients:
\newline
\begin{enumerate}
\item{A \textbf{statistical model} is a family of distributions $P$, indexed by a parameter $\theta$. We write $$ P = \{\mathbb{P}_{\theta} : \theta \in \Omega\}$$}

Here $\theta$ is the parameter, $\Omega$ is the parameter space, and each $\mathbb{P}_{\theta}$ is a distribution.\newline

$P$ is the class of distributions to which we believe our random sample $X$ belongs. In other words, we assume that the data $X$ come from some $\mathbb{P}_{\theta} \in P$ but that the true $\theta$ is unknown. \newline 

The fact that we don't know $\theta$ captures our uncertainty about the problem.    
 
\end{enumerate}
\end{frame}

% Framework 2
\begin{frame}
\frametitle{Decision Theory Framework}
\textbf{Example 1} (Weighted coin flips) \newline
\newline
Observe a sequence of coin flips $X_1,\dots,X_n \in \{0,1\}$ where 0 encodes tailes and 1 encodes heads. 
\newline
\newline
It's a weighted coin, so I don't know how often I expect heads to arrive. The goal is to estimate the probability of heads given the observations. 
\newline
\newline
To do this we model this process as independent draws from a Bernoulli distribution: $$P = \{\text{Ber}(\theta) : \theta \in [0,1] = \Omega \}$$
\newline
In this case, $\mathbb{P}_{\theta} (X_i = 1) = \theta$.

\end{frame}

% Framework 3
\begin{frame}
\frametitle{Decision Theory Framework}
\begin{enumerate}
\setcounter{enumi}{1}
\item{A \textbf{decision procedure} $\delta$ is a map from $\mathcal{X}$ (the sample space) to the decision space $\mathcal{D}$\newline
\newline
\textbf{Example 2} (Weighted coin flips)
\newline
\newline
Taking $P = \{\text{Ber}(\theta) : \theta \in [0,1] = \Omega \}$ as before, we may be interested in estimating $\theta$ or testing hypotheses based on $\theta$.
\newline
\begin{enumerate}[(a)]
\item{Estimating $\theta$: the decision space is $\mathcal{D} = [0,1]$, and the decision procedure might be $\delta(X) = \frac{1}{n} \sum^n_{i=1} X_i$. This procedure is an example of an \textbf{estimator}.}
\newline
\item{Accept or rejecting the hypothesis $\theta > 1/2$: the decision space is $\mathcal{D} = \{\text{accept}, \text{ reject}\}$, and one possible decision procedure is $\delta(X) = "\text{reject if} \frac{1}{n} \sum^n_{i=1} X_i \leq 1/2, \text{accept otherwise}"$ This procedure is an example of a \textbf{hypothesis test}.}
\end{enumerate}
}
\end{enumerate}
\end{frame}

% Framework 4
\begin{frame}
\frametitle{Decision Theory Framework}
\begin{enumerate}
\setcounter{enumi}{2}
\item{A \textbf{loss function} is a mapping $L: \Omega \times \mathcal{D} \rightarrow \mathbb{R}^{+}$. 
\newline
\newline 
$L(\theta, d)$ represents the penalty for making the decision $d$ when $\theta$ is in fact the true parameter for the distribution generating the data. 
\newline
\newline 
The goal is to assign penalties for bad decisions.
\newline
\newline 
\textbf{Example 3} (Squared-error loss). 
\newline
\newline 
For estimating a real-valued parameter $\theta$ with decision $d \in \mathbb{R} = \mathcal{D}$, a common loss function is the squared-error loss
$$ L(\theta, d) = (\theta - d)^2$$ 
}	
\end{enumerate}

	
\end{frame}



% Analyzing Procedures 1
\begin{frame}
\end{frame}

% Analyzing Procedures 2
\begin{frame}
\end{frame}

% Analyzing Procedures 3
\begin{frame}
\end{frame}

\end{document}
