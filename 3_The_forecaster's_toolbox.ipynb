{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Some simple forecasting methods\n",
    "Some forecasting methods are extremly simple and surprisingly effective.\n",
    "These methods are used as bechmarks.\n",
    "\n",
    "### (a)  Average method\n",
    "All future values are equall to the average (or mean) of the historical data.If the historical data is denoted by $y_1,.....,y_T$ then we can write\n",
    "the forecasts as \n",
    "$$\\hat{y}_{T+h|T} = (y_1+....+y_T)/T $$\n",
    "\n",
    "### (b) Naive method\n",
    "We simply set all forecasts to be the value of the last observation. \n",
    "That is , $$\\hat{y}_{T+h|T} = y_T$$\n",
    "This method works __remarkably well__ for many __economic__ and __financial__ time series.\n",
    "\n",
    "__THOUGHT__ Could this be the basis of foreward fill as the pre-processing tool to handle the missing data in financial time series?\n",
    "\n",
    "### (c) Seasonal naive method\n",
    "Each forecast is set to be equal to the last observed value from the same season of the year ( e.g., the same month of the previous year). The simple method is __useful__ for highly __seasonal__ data.\n",
    "$$\\hat{y}_{T+h|T} = y_{T+h-m(k+1)}$$, \n",
    "where $m=$ the seasonal period, and $k$ is the integer part of $(h-1)/m$ (i.e. the number of complete years in the forecast period prior to time T+h).  \n",
    "An easy example , with monthly data, the forecast for all future February values is equal to the last observed February value.\n",
    "\n",
    "### (d) Drift method\n",
    "A variation on the na√Øve method is to allow the forecasts to increase or decrease over time, where the amount of change over time (called the drift) is set to be the average change seen in the historical data\n",
    "$$\\hat{y}_{T+h|T} = y_T+ \\frac{h}{T-1}\\sum_{t=2}^{T}(y_t - y_{t-1}) = y_T + h(\\frac{y_t-y_1}{T-1}) $$\n",
    "\n",
    "This is __equivalent__ to drawing a __line__ between the __first and last observation__ , and extrapolating it into the future.\n",
    "\n",
    "__THOUGHT__ seems very similar to the methods employed in technical analysis of price movements.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "__ Any forecasting method developed should be better than these simple method.__\n",
    "\n",
    "__Alternatives: Repeated Random Sampling, Monte Carlo? etc__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Transformations and adjustements\n",
    "\n",
    "The purpose of adjustments and transformations is to simplify the patterns in the historical data by \n",
    "* __removing__ known sources of variation , or ,\n",
    "* by __making__ the pattern more consistent across the whole data set\n",
    "\n",
    "### (a) Calender adjustments \n",
    "\n",
    "Variation seen in seasonal data may be due to simple calendar effects.\n",
    "\n",
    "Examples. Variation of total monthly sales at store might not be a good choice due to variation in calender days and store holidays in a month. Rather modelling average sales by open day could be a better variable. \n",
    "\n",
    "### (b) Population adjustments\n",
    "\n",
    "Any data that are affected by population changes can be adjusted to give per-capita data. That is, consider the data per person (or per thousand people, or per million people) rather than the total. \n",
    "Examples. Popular stats like internet users in a country per centage of total population, girl child count per 1000 boys (sex - ratio studies) , or number of atms by a bank per 1,000,000 customers.\n",
    "\n",
    "__Thought__ There is always a rationale to think it in terms of some normalising population count. But I think it applies to more general variables like price per sf ? It could be thought of population as quantity/count.\n",
    "\n",
    "### (c) Inflation adjustments\n",
    "\n",
    "Financial time series data involving price may need to be adjusted for inflation. (As the value of population a given money can buy changes with time). \n",
    "\n",
    "For example. popular historical quotes for public projects is always quoted in today's term of currency (inflation adjusted). \n",
    "\n",
    "\n",
    "To make these adjustments, a price index is used. If $z_t$ denotes the price index and  $y_t$ denotes the original house price in year $t$ , then $x_t = y_t / z_t * z_{2020} $ gives the adjusted house price at year 2020 dollar values.\n",
    "\n",
    "__HPI__ (home price index) is used for real estate price adjustments.\n",
    "\n",
    "__Though__ when we use __excess return__  ,we do have a notion in mind to make returns comparable along long time horizons, could that be considered deriving from similar notion.\n",
    "\n",
    "\n",
    "### (d) Box - Cox Transformations\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.power_transform.html#r742a88cfa144-1\n",
    "\n",
    "## Residual auto correlation tests\n",
    "\n",
    "https://www.statsmodels.org/stable/generated/statsmodels.stats.diagnostic.acorr_ljungbox.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class sample:\n",
    "    def __init__(self):\n",
    "        print(\"This is a sample class\")\n",
    "        \n",
    "    def _print_hello(self,name):\n",
    "        print(f\"Hello {name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a sample class\n"
     ]
    }
   ],
   "source": [
    "s = sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello shivam\n"
     ]
    }
   ],
   "source": [
    "s._print_hello(\"shivam\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "x = np.random.randint(0,10,(10))\n",
    "\n",
    "print (x)\n",
    "for fact in ['x']:\n",
    "    vars()[fact+\"Mean\"] = np.mean(vars()[fact])\n",
    "for fact in ['x']:\n",
    "    vars()[fact] = vars()[fact] - vars()[fact+'Mean']\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.3"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xMean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
